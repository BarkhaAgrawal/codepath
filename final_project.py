# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ciu6GUe6heNxbelNK5w3D46ghYUOrihi
"""

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

import numpy as np
import pandas as pd
from collections import Counter 
import string
import random

path = F"/content/gdrive/My Drive/Data100 Proj4/dataset 2/Pride-and-Prejudice_1342-master/1342.txt"

file = open(path, "rt")
data = file.read()
words = data.split()

print('Number of words in text file :', len(words))

def getTotalNumberOfWords(filepath):
  file = open(filepath, "rt")
  data = file.read()
  words = data.split()
  table = str.maketrans('', '', string.punctuation)
  stripped = [w.translate(table) for w in words]
  print('Number of words in text file :', len(stripped))
  return len(stripped)

getTotalNumberOfWords(path)

def getTotalUniqueWords(filepath):
  file = open(filepath, "rt")
  data = file.read()
  words = data.split()
  table = str.maketrans('', '', string.punctuation)
  stripped = [w.translate(table) for w in words]
  uniquewords = set()
  for word in stripped:
    uniquewords.add(word)
  print('Number of words in text file :', len(uniquewords))
  return len(uniquewords)

getTotalUniqueWords(path)

def get20MostFrequentWords(filepath):
  file = open(filepath, "rt")
  data = file.read()
  words = data.split()
  table = str.maketrans('', '', string.punctuation)
  stripped = [w.translate(table) for w in words]
  c = Counter(stripped) 
  m = sorted(c.items(), key=lambda pair: pair[1], reverse=True)
  for i in range(20):
    m[i] = list(m[i])
  return m[0:20]

print(get20MostFrequentWords(path))

mostCommonWordsPath = F"/content/gdrive/My Drive/Data100 Proj4/dataset 2/Pride-and-Prejudice_1342-master/1-1000.txt"

file = open(mostCommonWordsPath, "rt")
data = file.read()
mostcommonwords = data.split()

def get20MostInterestingFrequentWords(path,k):
  file = open(path, "rt")
  data = file.read()
  words = data.split()
  table = str.maketrans('', '', string.punctuation)
  stripped = [w.translate(table) for w in words]
  stripped = [w.lower() for w in stripped]
  c = Counter(stripped) 
  c1 = [(word, count) for word, count in c.items() if word not in mostcommonwords[0:k]]
  m = sorted(c1, key=lambda pair: pair[1], reverse=True)
  for i in range(20):
    m[i] = list(m[i])
  return m[0:20]

get20MostInterestingFrequentWords(path,1000)

def get20LeastFrequentWords(path,k):
  file = open(path, "rt")
  data = file.read()
  words = data.split()
  table = str.maketrans('', '', string.punctuation)
  stripped = [w.translate(table) for w in words]
  stripped = [w.lower() for w in stripped]
  c = Counter(stripped) 
  c1 = [(word, count) for word, count in c.items() if word not in mostcommonwords[0:k]]
  m = sorted(c1, key=lambda pair: pair[1])
  for i in range(20):
    m[i] = list(m[i])
  return m[0:20]

get20LeastFrequentWords(path,1000)

def getFrequencyOfWord(searchword):
  file = open(path, "rt")
  data = file.read()
  chapters = data.split('Chapter')
  result = []
  for ch in chapters[1:]:
    words = ch.split()
    table = str.maketrans('', '', string.punctuation)
    stripped = [w.translate(table) for w in words]
    stripped = [w.lower() for w in stripped]
    c = Counter(stripped) 
    result.append(c[searchword])
  return result

print((getFrequencyOfWord("collins")))

def getChapterQuoteAppears(quote):
  file = open(path, "rt")
  data = file.read()
  chapters = data.split('Chapter')
  result = []
  i = 1
  for ch in chapters[1:]:
    if quote in ch:
      return i
    i+=1
  return -1

getChapterQuoteAppears("I hope Mr. Bingley will like it, Lizzy.")

def generateSentence():
  file = open(path, "rt")
  data = file.read()
  result = []
  words = data.split()
  table = str.maketrans('', '', string.punctuation)
  stripped = [w.translate(table) for w in words]
  result.append("The")
  for i in range(1,20):
    indices = [index for index, element in enumerate(words) if element == result[i-1]]
    new_list = [x+1 for x in indices]
    random_num = random.choice(new_list) 
    result.append(words[random_num])
  return " ".join(result)

generateSentence()

